/*************************************************************************************************

Welcome to Baml! To use this generated code, please run one of the following:

$ npm install @boundaryml/baml
$ yarn add @boundaryml/baml
$ pnpm add @boundaryml/baml

*************************************************************************************************/

// This file was generated by BAML: please do not edit it. Instead, edit the
// BAML files and re-generate this code using: baml-cli generate
// You can install baml-cli with:
//  $ npm install @boundaryml/baml
//
/* eslint-disable */
// tslint:disable
// @ts-nocheck
// biome-ignore format: autogenerated code

const fileMap = {
  
  "clients.baml": "// Learn more about clients at https://docs.boundaryml.com/docs/snippets/clients/overview\n\n// Using the new OpenAI Responses API for enhanced formatting\nclient<llm> CustomGPT5 {\n  provider openai-responses\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\nclient<llm> CustomGPT5Mini {\n  provider openai-responses\n  retry_policy Exponential\n  options {\n    model \"gpt-5-mini\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Openai with chat completion\nclient<llm> CustomGPT5Chat {\n  provider openai\n  options {\n    model \"gpt-5\"\n    api_key env.OPENAI_API_KEY\n  }\n}\n\n// Latest Anthropic Claude 4 models\nclient<llm> CustomOpus4 {\n  provider anthropic\n  options {\n    model \"claude-opus-4-1-20250805\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomSonnet4 {\n  provider anthropic\n  options {\n    model \"claude-sonnet-4-20250514\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\nclient<llm> CustomHaiku {\n  provider anthropic\n  retry_policy Constant\n  options {\n    model \"claude-3-5-haiku-20241022\"\n    api_key env.ANTHROPIC_API_KEY\n  }\n}\n\n// Example Google AI client (uncomment to use)\n// client<llm> CustomGemini {\n//   provider google-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     api_key env.GOOGLE_API_KEY\n//   }\n// }\n\n// Example AWS Bedrock client (uncomment to use)\n// client<llm> CustomBedrock {\n//   provider aws-bedrock\n//   options {\n//     model \"anthropic.claude-sonnet-4-20250514-v1:0\"\n//     region \"us-east-1\"\n//     // AWS credentials are auto-detected from env vars\n//   }\n// }\n\n// Example Azure OpenAI client (uncomment to use)\n// client<llm> CustomAzure {\n//   provider azure-openai\n//   options {\n//     model \"gpt-5\"\n//     api_key env.AZURE_OPENAI_API_KEY\n//     base_url \"https://MY_RESOURCE_NAME.openai.azure.com/openai/deployments/MY_DEPLOYMENT_ID\"\n//     api_version \"2024-10-01-preview\"\n//   }\n// }\n\n// Example Vertex AI client (uncomment to use)\n// client<llm> CustomVertex {\n//   provider vertex-ai\n//   options {\n//     model \"gemini-2.5-pro\"\n//     location \"us-central1\"\n//     // Uses Google Cloud Application Default Credentials\n//   }\n// }\n\n// Example Ollama client for local models (uncomment to use)\n// client<llm> CustomOllama {\n//   provider openai-generic\n//   options {\n//     base_url \"http://localhost:11434/v1\"\n//     model \"llama4\"\n//     default_role \"user\" // Most local models prefer the user role\n//     // No API key needed for local Ollama\n//   }\n// }\n\n// https://docs.boundaryml.com/docs/snippets/clients/round-robin\nclient<llm> CustomFast {\n  provider round-robin\n  options {\n    // This will alternate between the two clients\n    strategy [CustomGPT5Mini, CustomHaiku]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/fallback\nclient<llm> OpenaiFallback {\n  provider fallback\n  options {\n    // This will try the clients in order until one succeeds\n    strategy [CustomGPT5Mini, CustomGPT5]\n  }\n}\n\n// https://docs.boundaryml.com/docs/snippets/clients/retry\nretry_policy Constant {\n  max_retries 3\n  strategy {\n    type constant_delay\n    delay_ms 200\n  }\n}\n\nretry_policy Exponential {\n  max_retries 2\n  strategy {\n    type exponential_backoff\n    delay_ms 300\n    multiplier 1.5\n    max_delay_ms 10000\n  }\n}",
  "generators.baml": "// This helps use auto generate libraries you can use in the language of\n// your choice. You can have multiple generators if you use multiple languages.\n// Just ensure that the output_dir is different for each generator.\ngenerator target {\n    // Valid values: \"python/pydantic\", \"typescript\", \"ruby/sorbet\", \"rest/openapi\"\n    output_type \"typescript\"\n\n    // Where the generated code will be saved (relative to baml_src/)\n    output_dir \"../\"\n\n    // The version of the BAML package you have installed (e.g. same version as your baml-py or @boundaryml/baml).\n    // The BAML VSCode extension version should also match this version.\n    version \"0.214.0\"\n\n    // Valid values: \"sync\", \"async\"\n    // This controls what `b.FunctionName()` will be (sync or async).\n    default_client_mode async\n}\n",
  "resume.baml": "// Defining a data model.\nclass Resume {\n  name string\n  email string\n  experience string[]\n  skills string[]\n}\n\n// Create a function to extract the resume from a string.\nfunction ExtractResume(resume: string) -> Resume {\n  // Specify a client as provider/model-name\n  // You can also use custom LLM params with a custom client name from clients.baml like \"client CustomGPT5\" or \"client CustomSonnet4\"\n  client \"openai-responses/gpt-5-mini\" // Set OPENAI_API_KEY to use this client.\n  prompt #\"\n    Extract from this content:\n    {{ resume }}\n\n    {{ ctx.output_format }}\n  \"#\n}\n\n\n\n// Test the function with a sample resume. Open the VSCode playground to run this.\ntest vaibhav_resume {\n  functions [ExtractResume]\n  args {\n    resume #\"\n      Vaibhav Gupta\n      vbv@boundaryml.com\n\n      Experience:\n      - Founder at BoundaryML\n      - CV Engineer at Google\n      - CV Engineer at Microsoft\n\n      Skills:\n      - Rust\n      - C++\n    \"#\n  }\n}\n",
  "skills/research/decompose.baml": "// Research Skill - Query Decomposition\n// Split query into parallel, non-overlapping sub-queries\n\nclass DecompositionRequest {\n  query string\n  depth int @description(\"1=quick, 2=standard, 3=deep, 4=extensive\")\n  validation ValidationResult @description(\"From validation phase\")\n}\n\nclass SubQuery {\n  query string @description(\"Specific sub-query to research\")\n  focus string @description(\"What aspect this covers\")\n  priority int @description(\"1=essential, 2=important, 3=supplementary\")\n  boundary string @description(\"What NOT to include (prevents overlap)\")\n}\n\nclass DecompositionResult {\n  primary_queries SubQuery[] @description(\"Core research queries\")\n  validation_queries SubQuery[] @description(\"Fact-checking queries\")\n  edge_queries SubQuery[]? @description(\"Edge cases and controversies\")\n}\n\nfunction DecomposeQuery(req: DecompositionRequest) -> DecompositionResult {\n  client CustomGPT5Mini\n  prompt #\"\n    Decompose this research query into parallel sub-queries.\n    \n    Main Query: {{ req.query }}\n    Depth Level: {{ req.depth }} (1=quick/2 queries, 2=standard/4-6, 3=deep/8-10, 4=extensive/12-16)\n    \n    Validated Structure:\n    - Topics: {{ req.validation.topics }}\n    - Relationship: {{ req.validation.relationship }}\n    - Time Period: {{ req.validation.time_period }}\n    - Primary Sources: {{ req.validation.primary_sources }}\n    \n    Generate sub-queries that:\n    1. Cover all aspects without overlap\n    2. Have clear boundaries (what NOT to research)\n    3. Are optimized for parallel execution\n    4. Include validation/fact-checking queries\n    5. Match depth level (generate appropriate number of queries)\n    \n    For each query specify:\n    - Specific question to answer\n    - What aspect it covers\n    - Priority (1=must have, 2=important, 3=nice to have)\n    - Boundary (what to exclude to prevent overlap)\n    \n    {{ ctx.output_format }}\n  \"#\n}\n\ntest DecomposeStandard {\n  functions [DecomposeQuery]\n  args {\n    req {\n      query \"Research AI safety developments in 2025\"\n      depth 2\n      validation {\n        is_clear true\n        topics [\"AI safety\", \"alignment research\"]\n        relationship \"coordinated\"\n        time_period \"2025\"\n        primary_sources [\"arxiv.org\", \"anthropic.com\"]\n        recommended_structure \"Topic-based parallel research\"\n        clarification_needed null\n      }\n    }\n  }\n}\n",
  "skills/research/factcheck.baml": "// Research Skill - Fact Checking\n// Verify claims before synthesis\n\nclass FactCheckRequest {\n  claims string[] @description(\"Claims to verify\")\n  context string @description(\"Context around these claims\")\n}\n\nclass FactCheckResult {\n  claim string\n  verdict string @description(\"VERIFIED|PARTIALLY_TRUE|MISLEADING|FALSE|UNVERIFIABLE\")\n  explanation string @description(\"Why this verdict\")\n  sources Source[] @description(\"Sources used for verification\")\n  nuance string? @description(\"Important context or caveats\")\n}\n\nclass FactCheckResponse {\n  results FactCheckResult[]\n  overall_accuracy float @description(\"0-1 overall accuracy of claims\")\n  red_flags string[] @description(\"Major concerns identified\")\n}\n\nfunction FactCheckClaims(req: FactCheckRequest) -> FactCheckResponse {\n  client CustomSonnet4\n  prompt #\"\n    You are a rigorous fact-checker. Verify these claims:\n    \n    {% for claim in req.claims %}\n    {{ loop.index }}. {{ claim }}\n    {% endfor %}\n    \n    Context: {{ req.context }}\n    \n    For each claim:\n    1. Search for authoritative sources\n    2. Determine verdict:\n       - VERIFIED: Multiple authoritative sources confirm\n       - PARTIALLY_TRUE: True but missing important context\n       - MISLEADING: Technically true but misleading\n       - FALSE: Contradicted by authoritative sources\n       - UNVERIFIABLE: Cannot verify with available information\n    3. Explain your reasoning\n    4. Note any nuance or caveats\n    5. Cite sources with authority scores\n    \n    Be rigorous. Say UNVERIFIABLE rather than guessing.\n    \n    Red flags to watch for:\n    - Single anonymous sources\n    - Conflation of separate events\n    - Outdated information presented as current\n    - Speculation presented as fact\n    \n    {{ ctx.output_format }}\n  \"#\n}\n\ntest FactCheckCrypto {\n  functions [FactCheckClaims]\n  args {\n    req {\n      claims [\n        \"OpenAI released GPT-5 in 2025\",\n        \"Claude 4 outperforms GPT-5 on reasoning benchmarks\"\n      ]\n      context \"AI model releases in 2025\"\n    }\n  }\n}\n",
  "skills/research/research.baml": "// Research Skill - Core Research Function\n// Executes individual research queries with source attribution\n\nclass ResearchRequest {\n  query string @description(\"The specific research query\")\n  focus string @description(\"What aspect to focus on\")\n  boundary string @description(\"What NOT to include\")\n  depth int @description(\"1-4 depth level\")\n  existing_knowledge string? @description(\"What we already know\")\n}\n\nfunction ResearchTopic(req: ResearchRequest) -> ResearchResult {\n  client CustomSonnet4\n  prompt #\"\n    You are an expert researcher conducting thorough investigation.\n    \n    Research Query: {{ req.query }}\n    Focus Area: {{ req.focus }}\n    Depth Level: {{ req.depth }}\n    \n    BOUNDARIES (DO NOT research - other agents handle):\n    {{ req.boundary }}\n    \n    {% if req.existing_knowledge %}\n    Existing Knowledge: {{ req.existing_knowledge }}\n    {% endif %}\n    \n    Instructions:\n    1. Provide clear, factual findings with source attribution\n    2. Rate confidence for each finding:\n       - HIGH: Multiple authoritative sources agree\n       - MEDIUM: Single authoritative source\n       - LOW: Limited or conflicting sources\n       - UNVERIFIED: Cannot verify\n    3. Identify {{ req.depth * 2 }} key findings minimum\n    4. Note contradictions or controversies\n    5. Identify information gaps\n    6. Suggest {{ req.depth }} follow-up directions\n    7. Assess quality (coverage, confidence, depth)\n    \n    Source Authority Scoring:\n    - 0.9-1.0: Government/regulatory, peer-reviewed journals\n    - 0.7-0.9: Major news outlets, industry publications\n    - 0.5-0.7: Industry blogs, analyst reports\n    - 0.3-0.5: Social media, forums\n    - 0.0-0.3: Anonymous sources, speculation\n    \n    {{ ctx.output_format }}\n  \"#\n}\n\ntest ResearchAISafety {\n  functions [ResearchTopic]\n  args {\n    req {\n      query \"Latest developments in AI alignment research\"\n      focus \"Technical approaches and breakthroughs\"\n      boundary \"Do not cover policy/regulation\"\n      depth 2\n      existing_knowledge null\n    }\n  }\n}\n",
  "skills/research/synthesize.baml": "// Research Skill - Synthesis\n// Combine results into tiered output\n\nclass SynthesisRequest {\n  original_query string\n  research_results ResearchResult[]\n  fact_check FactCheckResponse?\n  output_format string @description(\"executive|full|bullets|table\")\n}\n\nclass ExecutiveBrief {\n  title string\n  date string\n  research_question string\n  key_findings Finding[] @description(\"Top 3-5 findings only\")\n  critical_distinctions string[] @description(\"What IS true vs NOT\")\n  confidence_summary string\n  strategic_implications string[]\n  recommended_actions string[]\n  read_time string\n}\n\nclass SynthesisResult {\n  executive_brief ExecutiveBrief @description(\"Tier 1: 500 words max\")\n  detailed_analysis string @description(\"Tier 2: Full markdown analysis\")\n  source_appendix string @description(\"Tier 3: Complete sources list\")\n  quality QualityMetrics\n}\n\nfunction SynthesizeFindings(req: SynthesisRequest) -> SynthesisResult {\n  client CustomGPT5\n  prompt #\"\n    Synthesize research results into tiered output.\n    \n    Original Query: {{ req.original_query }}\n    Output Format: {{ req.output_format }}\n    \n    Research Results:\n    {% for result in req.research_results %}\n    --- Research Stream {{ loop.index }} ---\n    Summary: {{ result.summary }}\n    Findings: \n    {% for f in result.key_findings %}\n    - {{ f.claim }} [{{ f.confidence }}]\n    {% endfor %}\n    Quality: {{ result.quality.overall_grade }}\n    {% endfor %}\n    \n    {% if req.fact_check %}\n    Fact-Check Results (Accuracy: {{ req.fact_check.overall_accuracy }}):\n    {% for r in req.fact_check.results %}\n    - {{ r.claim }}: {{ r.verdict }}\n    {% endfor %}\n    {% if req.fact_check.red_flags %}\n    Red Flags: {{ req.fact_check.red_flags }}\n    {% endif %}\n    {% endif %}\n    \n    Create THREE-TIER output:\n    \n    TIER 1 - EXECUTIVE BRIEF (500 words max):\n    - Clear title and date\n    - Research question restated\n    - Top 3-5 findings with confidence indicators (✅ HIGH, ⚠️ MEDIUM, ❓ LOW)\n    - What IS true vs what is NOT true\n    - Strategic implications\n    - Recommended actions\n    - Estimated read time\n    \n    TIER 2 - DETAILED ANALYSIS:\n    - Comprehensive coverage by topic\n    - All findings with supporting evidence\n    - Methodology description\n    - Risks and limitations\n    - Formatted as clean markdown\n    \n    TIER 3 - SOURCE APPENDIX:\n    - Complete list of sources with URLs\n    - Authority scores for each\n    - Full citations\n    \n    {{ ctx.output_format }}\n  \"#\n}\n\ntest SynthesizeSimple {\n  functions [SynthesizeFindings]\n  args {\n    req {\n      original_query \"AI safety developments\"\n      research_results [{\n        summary \"AI safety research has accelerated in 2025\"\n        key_findings [{\n          claim \"Anthropic released new interpretability tools\"\n          confidence \"HIGH\"\n          sources []\n          contradictions null\n        }]\n        sources []\n        gaps []\n        follow_ups []\n        quality {\n          coverage_score 75\n          confidence_score 80\n          depth_score 70\n          overall_grade \"B\"\n        }\n        methodology \"Web research and paper analysis\"\n      }]\n      fact_check null\n      output_format \"executive\"\n    }\n  }\n}\n",
  "skills/research/types.baml": "// Research Skill - Shared Types\n// These types are used across all research functions\n\nclass Source {\n  url string @description(\"Source URL\")\n  title string @description(\"Page or article title\")\n  snippet string @description(\"Relevant excerpt (100-200 words)\")\n  source_type string @description(\"primary|secondary|tertiary\")\n  authority_score float @description(\"0-1 authority/reliability score\")\n  recency string @description(\"Publication date or 'unknown'\")\n  bias_indicator string? @description(\"left|center|right|unknown\")\n}\n\nclass Finding {\n  claim string @description(\"The specific claim or finding\")\n  confidence string @description(\"HIGH|MEDIUM|LOW|UNVERIFIED\")\n  sources Source[] @description(\"Sources supporting this finding\")\n  contradictions string[]? @description(\"Any contradicting information found\")\n}\n\nclass ResearchGap {\n  topic string @description(\"What information is missing\")\n  importance string @description(\"CRITICAL|IMPORTANT|NICE_TO_HAVE\")\n  suggested_query string @description(\"Query to fill this gap\")\n}\n\nclass FollowUpSuggestion {\n  query string @description(\"Suggested follow-up research query\")\n  rationale string @description(\"Why this would be valuable\")\n  estimated_depth string @description(\"quick|standard|deep\")\n  priority int @description(\"1=highest, 3=lowest\")\n}\n\nclass QualityMetrics {\n  coverage_score int @description(\"0-100: breadth and depth of coverage\")\n  confidence_score int @description(\"0-100: source reliability and validation\")\n  depth_score int @description(\"0-100: analysis depth achieved\")\n  overall_grade string @description(\"A|B|C|D based on all scores\")\n}\n\nclass ResearchResult {\n  summary string @description(\"Executive summary (200-500 words)\")\n  key_findings Finding[] @description(\"Main findings with confidence levels\")\n  sources Source[] @description(\"All sources consulted\")\n  gaps ResearchGap[] @description(\"Information gaps identified\")\n  follow_ups FollowUpSuggestion[] @description(\"Suggested next research\")\n  quality QualityMetrics @description(\"Quality assessment\")\n  methodology string @description(\"Brief description of research approach\")\n}\n",
  "skills/research/validate.baml": "// Research Skill - Scope Validation\n// Quick validation to prevent wasted effort from ambiguous queries\n\nclass ValidationRequest {\n  query string @description(\"Original user query\")\n  context string? @description(\"Any additional context provided\")\n}\n\nclass ValidationResult {\n  is_clear bool @description(\"Is the query unambiguous?\")\n  topics string[] @description(\"Distinct topics identified\")\n  relationship string @description(\"coordinated|separate|comparison|unclear\")\n  time_period string @description(\"Specific dates or 'unspecified'\")\n  primary_sources string[] @description(\"Key sources to check first\")\n  recommended_structure string @description(\"How to structure the research\")\n  clarification_needed string[]? @description(\"Questions to ask user if unclear\")\n}\n\nfunction ValidateResearchScope(req: ValidationRequest) -> ValidationResult {\n  client CustomHaiku\n  prompt #\"\n    You are a research planning assistant. Analyze this research request.\n    \n    Query: {{ req.query }}\n    {% if req.context %}Context: {{ req.context }}{% endif %}\n    \n    Determine:\n    1. Is this query clear and unambiguous?\n    2. How many distinct topics are mentioned?\n    3. Are topics related/coordinated or separate events?\n    4. Is there a specific time period?\n    5. What are the primary authoritative sources to check?\n    6. How should research be structured?\n    7. What clarifying questions would help (if any)?\n    \n    Be concise. This is a quick validation step.\n    \n    {{ ctx.output_format }}\n  \"#\n}\n\ntest ValidateSimple {\n  functions [ValidateResearchScope]\n  args {\n    req {\n      query \"Research AI safety developments\"\n      context null\n    }\n  }\n}\n\ntest ValidateAmbiguous {\n  functions [ValidateResearchScope]\n  args {\n    req {\n      query \"Research the Vanguard and Singapore announcements about XRP\"\n      context \"Recent news from December 2025\"\n    }\n  }\n}\n",
}
export const getBamlFiles = () => {
    return fileMap;
}